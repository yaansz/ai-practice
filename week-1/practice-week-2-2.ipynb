{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspirador de Pó\n",
    "\n",
    "**Problema:** Implemente um simulador de ambiente de medição de desempenho para o mundo do aspirador de pó. Sua implementação deve ser modular, de forma que os sensores, os atuadores e as características do ambiente (tamanho, localização da sujeira, ... ) possam ser alterados com facilidade\n",
    "\n",
    "a) Medida de Desempenho A medida de desempenho oferece o prêmio de um ponto para cada sala limpa em cada período de tempo ao longo de uma duração de mil períodos de tempo.\n",
    "\n",
    "b) Conhecimento a priori A geografia do ambiente não é conhecida a priori (Figura 2.2), a distribuição da sujeira e a posição inicial do agente não são previamente conhecidas. O ambiente para o agente é parcialmente observável. A aspiração limpa o quadrado atual. As ações esquerda e direita movem o agente para a esquerda e para a direita, exceto quando isso tenta levar o agente para fora do ambiente; nesse caso, o agente permanece onde está. \n",
    "\n",
    "c) Ações do agente Esquerda, Direita, Limpar e NoOp (fazer nada).\n",
    "\n",
    "d) Percepções O agente percebe corretamente sua posição e se esta posição contém sujeita.\n",
    "\n",
    "fig 2.7\n",
    "\n",
    "Ambiente um mundo do aspirador de pó com apenas duas salas. Estas que por sua vez, podem estar limpas ou não conforme o tempo passa. A sujeira pode surgir de modo espontâneo por fins de simulação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurações básicas do programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logs >>>\n",
    "import logging\n",
    "import os\n",
    "from colorlog import ColoredFormatter\n",
    "\n",
    "\"\"\"\n",
    "Dictionary that store all possible floor state values\n",
    "\"\"\"\n",
    "FLOOR_STATE = {\"clean\" : 0, \"dirty\" : 1}\n",
    "AGENT_STATE = {\"right\": 1, \"left\": -1, \"clean\": 2, \"NoOp\": 0}\n",
    "\n",
    "\n",
    "def init_log(log_level):\n",
    "    # Initializing the logger\n",
    "    logFormat = \"%(message)s\"\n",
    "    formatter = ColoredFormatter(\"%(log_color)s\" + logFormat)\n",
    "    \n",
    "    # Terminal\n",
    "    stream = logging.StreamHandler()\n",
    "    stream.setFormatter(formatter)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=log_level,\n",
    "        format=logFormat,\n",
    "        handlers=[\n",
    "            stream\n",
    "        ]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agente Burro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing\n",
    "\n",
    "class DumbAgent(Agent):\n",
    "\n",
    "    def __init__(self, location: int):\n",
    "        # Default init\n",
    "        self.performance = 0\n",
    "\n",
    "        # IDK ABOUT THAT\n",
    "        self.direction = 1\n",
    "        \n",
    "        self.location = location\n",
    "        \n",
    "    def act(self, env):\n",
    "        if env.rooms[self.location] == FLOOR_STATE[\"dirty\"]:\n",
    "            env.rooms[self.location] = FLOOR_STATE[\"clean\"]\n",
    "            \n",
    "            return AGENT_STATE[\"clean\"]\n",
    "        else:\n",
    "            self.direction = random.choice([AGENT_STATE[\"right\"], AGENT_STATE[\"left\"]])\n",
    "\n",
    "            if self.direction == AGENT_STATE[\"left\"] and self.location == 0:\n",
    "                self.direction = AGENT_STATE[\"NoOp\"]\n",
    "            \n",
    "            elif self.direction == AGENT_STATE[\"right\"] and self.location == len(env.rooms) - 1:\n",
    "                self.direction = AGENT_STATE[\"NoOp\"]\n",
    "\n",
    "            self.location += self.direction\n",
    "        return self.direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe do Agente Inteligente\n",
    "\n",
    "Classe responsável por armazenar e saber se comportar dado o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing\n",
    "import logging\n",
    "\n",
    "class SmartAgent(Agent):\n",
    "\n",
    "    def __init__(self, location: int):\n",
    "        # Default init\n",
    "        self.performance = 0\n",
    "\n",
    "        # IDK ABOUT THAT\n",
    "        self.direction = 1\n",
    "        \n",
    "        self.location = location\n",
    "        \n",
    "        \n",
    "    def act(self, env):\n",
    "        if env.rooms[self.location] == FLOOR_STATE[\"dirty\"]:\n",
    "            env.rooms[self.location] = FLOOR_STATE[\"clean\"]\n",
    "            \n",
    "            logging.debug(\"Limpando a sala \" + str(self.location))\n",
    "            \n",
    "            return AGENT_STATE[\"clean\"]\n",
    "        else:\n",
    "            if self.location == 0:\n",
    "                self.direction = AGENT_STATE[\"right\"]\n",
    "            elif self.location == len(env.rooms) - 1:\n",
    "                self.direction = AGENT_STATE[\"left\"]\n",
    "            else:\n",
    "                right = 0\n",
    "                left = 0\n",
    "                # Encontrar a sujeira mais próxima\n",
    "                for i in range(self.location - 1, -1, -1):\n",
    "                    left += 1\n",
    "                    \n",
    "                    if env.rooms[i] == FLOOR_STATE[\"dirty\"]:\n",
    "                        break\n",
    "                for i in range(self.location + 1, len(env.rooms)):\n",
    "                    right += 1\n",
    "                    if env.rooms[i] == FLOOR_STATE[\"dirty\"]:\n",
    "                        break\n",
    "                \n",
    "                self.direction = 1 if right < left else -1\n",
    "            \n",
    "            logging.debug(\"Movendo de \" + str(self.location) + \" para \" + str(self.location + self.direction))\n",
    "            self.location += self.direction\n",
    "            \n",
    "            \n",
    "        return self.direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambiente\n",
    "O ambiente será representado a partir de um vetor 1D (Pois possui apenas ações de direita, esquerda, limpar, nada). Esse vetor pode aumentar e diminuir, não importando o tamanho inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import typing\n",
    "from typing import Callable\n",
    "from typing import Union\n",
    "\n",
    "class Environment:\n",
    "\n",
    "    def __init__(self, rooms: Union[int, list], dirty_probability: int, agent: Agent):\n",
    "        # 0 - clean / 1 - dirty\n",
    "        if type(rooms) is int:\n",
    "            self.rooms = [random.choice(list(FLOOR_STATE.values())) for i in range(0, rooms)]\n",
    "        else:\n",
    "            self.rooms = rooms.copy()\n",
    "        \n",
    "        self.size = len(self.rooms)\n",
    "        \n",
    "\n",
    "        self.agent = agent\n",
    "\n",
    "        # Artificial Env Controller\n",
    "        self.dirty_probability = dirty_probability\n",
    "    \n",
    "    \n",
    "    def floor_is_clean(self):\n",
    "        \n",
    "        for floor in self.rooms:\n",
    "            if floor == FLOOR_STATE[\"dirty\"]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    \n",
    "    def update(self):\n",
    "        \n",
    "        choice = self.agent.act(self)\n",
    "\n",
    "        if choice == AGENT_STATE[\"clean\"]:\n",
    "            self.agent.performance += 1\n",
    "        \n",
    "        elif choice is AGENT_STATE[\"right\"] or choice is AGENT_STATE[\"left\"]:\n",
    "            self.agent.performance -= 1\n",
    "        # Raise an exception ????????\n",
    "        \n",
    "        return\n",
    "\n",
    "\n",
    "    def artificial_env_changes(self):\n",
    "        \n",
    "        # Rand to decide if we should dirty someplace\n",
    "        if random.randint(0, 100) < self.dirty_probability: \n",
    "            self.rooms[random.randrange(0, self.size)] = 1\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        message = \"\"\n",
    "        for i in range(len(self.rooms)):\n",
    "            show = str(i) + \":C\" if self.rooms[i] == FLOOR_STATE[\"clean\"] else str(i) + \":D\"\n",
    "            message += \" | \" + show\n",
    "        \n",
    "        message += \" | -> agent position: \" + str(self.agent.location)\n",
    "        return message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mDumb Agent: \u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 72, Sala: [0, 0], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 82, Sala: [0, 0], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 91, Sala: [0, 1], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 67, Sala: [0, 1], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 48, Sala: [1, 0], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 75, Sala: [1, 0], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 94, Sala: [1, 1], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 43, Sala: [1, 1], Inicial: 1\u001b[0m\n",
      "\u001b[32mMédia da pontuação: 71.5\u001b[0m\n",
      "\u001b[32mSmart Agent: \u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 174, Sala: [0, 0], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 188, Sala: [0, 0], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 196, Sala: [0, 1], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 179, Sala: [0, 1], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 188, Sala: [1, 0], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 171, Sala: [1, 0], Inicial: 1\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 212, Sala: [1, 1], Inicial: 0\u001b[0m\n",
      "\u001b[32mPassos: 1000, Pontuação: 183, Sala: [1, 1], Inicial: 1\u001b[0m\n",
      "\u001b[32mMédia da pontuação: 186.375\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def evaluate(env_config, agent_position, dirty_probability, times):\n",
    "    \n",
    "    env = Environment(env_config, dirty_probability, agent_position)\n",
    "    \n",
    "    for i in range(0, times):\n",
    "        # Play\n",
    "        logging.debug(env)\n",
    "        \n",
    "        env.update()\n",
    "        # Generate dirty\n",
    "        env.artificial_env_changes()\n",
    "    \n",
    "    return env.agent.performance\n",
    "\n",
    "def main():\n",
    "\n",
    "    performancesSmart = []\n",
    "    performancesDumb = []\n",
    "\n",
    "    env_possible = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "    agent_possible = [0, 1]\n",
    "\n",
    "    init_log(logging.INFO)\n",
    "\n",
    "    logging.info(\"Dumb Agent: \")\n",
    "    for env_config in env_possible:\n",
    "        for agent_position in agent_possible:\n",
    "            performancesDumb.append(evaluate(env_config, DumbAgent(agent_position), 50, 1000))\n",
    "            logging.info(f\"Passos: 1000, Pontuação: {performancesDumb[-1]}, Sala: {env_config}, Inicial: {agent_position}\")\n",
    "    logging.info(\"Média da pontuação: \" + str(sum(performancesDumb) / len(performancesDumb) ))\n",
    "\n",
    "\n",
    "    logging.info(\"Smart Agent: \")\n",
    "    for env_config in env_possible:\n",
    "        for agent_position in agent_possible:\n",
    "            performancesSmart.append(evaluate(env_config, SmartAgent(agent_position), 50, 1000))\n",
    "            logging.info(f\"Passos: 1000, Pontuação: {performancesSmart[-1]}, Sala: {env_config}, Inicial: {agent_position}\")\n",
    "    logging.info(\"Média da pontuação: \" + str(sum(performancesSmart) / len(performancesSmart) ))\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf2c428c96f876ce83dc4f776a166961696961df3fa7e5fedd7f64565516e345"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
